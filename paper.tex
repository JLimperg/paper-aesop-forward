\documentclass[runningheads]{llncs}

% TODO: standardise indices vs indexes
% TODO: standardise dots after equations
% TODO: rename variable maps to variable indices everywhere
% TODO: standardise Rocq vs Coq

\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage[british]{babel}
\usepackage{newunicodechar}
\usepackage{xcolor}
\usepackage{minted}
\usepackage{amsmath,amssymb}
\usepackage{mathtools}
\usepackage{graphicx}
\usepackage{pgfplots}
\usepackage{hyperref}
\usepackage{csquotes}
\usepackage[noend]{algorithm2e}
\usepackage{siunitx}
\usepackage{caption}
\usepackage{subcaption}

\renewcommand\UrlFont{\color{blue}\rmfamily}
\urlstyle{rm}
\def\orcid#1{{\href{http://orcid.org/#1}{\protect\raisebox{-1.25pt}{\protect\includegraphics{orcid.pdf}}}}}
\SetKw{KwIn}{in}
\SetKw{KwLet}{let}
\SetKw{KwYield}{yield}
\SetKwInOut{Input}{Input}
\SetKwInOut{Output}{Output}
\SetKwProg{Procedure}{Procedure}{}{}

\newunicodechar{₀}{\ensuremath{_{0}}}
\newunicodechar{₁}{\ensuremath{_{1}}}
\newunicodechar{₂}{\ensuremath{_{2}}}
\newunicodechar{₃}{\ensuremath{_{3}}}
\newunicodechar{₄}{\ensuremath{_{4}}}
\newunicodechar{₅}{\ensuremath{_{5}}}
\newunicodechar{₆}{\ensuremath{_{6}}}
\newunicodechar{₇}{\ensuremath{_{7}}}
\newunicodechar{₈}{\ensuremath{_{8}}}
\newunicodechar{₉}{\ensuremath{_{9}}}
\newunicodechar{ₙ}{\ensuremath{_{n}}}
\newunicodechar{ₘ}{\ensuremath{_{m}}}
\newunicodechar{ᵢ}{\ensuremath{_{i}}}
\newunicodechar{ⱼ}{\ensuremath{_{j}}}
\newunicodechar{ₗ}{\ensuremath{_{l}}}
\newunicodechar{ₖ}{\ensuremath{_{k}}}
\newunicodechar{α}{\ensuremath{\alpha}}
\newunicodechar{σ}{\ensuremath{\sigma}}
\newunicodechar{τ}{\ensuremath{\tau}}
\newunicodechar{λ}{\ensuremath{\lambda}}
\newunicodechar{μ}{\ensuremath{\mu}}
\newunicodechar{η}{\ensuremath{\eta}}
\newunicodechar{Γ}{\ensuremath{\Gamma}}
\newunicodechar{Δ}{\ensuremath{\Delta}}
\newunicodechar{Φ}{\ensuremath{\Phi}}
\newunicodechar{Ψ}{\ensuremath{\Psi}}
\newunicodechar{Ω}{\ensuremath{\Omega}}
\newunicodechar{∈}{\ensuremath{\in}}
\newunicodechar{∉}{\ensuremath{\notin}}
\newunicodechar{≡}{\ensuremath{\equiv}}
\newunicodechar{≢}{\ensuremath{\nequiv}}
\newunicodechar{≠}{\ensuremath{\neq}}
\newunicodechar{≤}{\ensuremath{\leq}}
\newunicodechar{≥}{\ensuremath{\geq}}
\newunicodechar{≺}{\ensuremath{\prec}}
\newunicodechar{≔}{\ensuremath{\coloneq}}
\newunicodechar{∧}{\ensuremath{\land}}
\newunicodechar{∨}{\ensuremath{\lor}}
\newunicodechar{∪}{\ensuremath{\cup}}
\newunicodechar{∩}{\ensuremath{\cap}}
\newunicodechar{⊆}{\ensuremath{\subseteq}}
\newunicodechar{⋃}{\ensuremath{\bigcup}}
\newunicodechar{→}{\ensuremath{\rightarrow}}
\newunicodechar{↔}{\ensuremath{\leftrightarrow}}
\newunicodechar{↦}{\ensuremath{\mapsto}}
\newunicodechar{⊢}{\ensuremath{\vdash}}
\newunicodechar{∅}{\ensuremath{\emptyset}}
\newunicodechar{∷}{\ensuremath{\mathbin{::}}}
\newunicodechar{⇒}{\ensuremath{\Rightarrow}}
\newunicodechar{ℕ}{\ensuremath{\mathbb{N}}}
\newunicodechar{⟨}{\ensuremath{\langle}}
\newunicodechar{⟩}{\ensuremath{\rangle}}
\newunicodechar{⊤}{\ensuremath{\top}}
\newunicodechar{⊥}{\ensuremath{\bot}}
\newunicodechar{×}{\ensuremath{\times}}

\newtheorem{lem}{Lemma}

\setminted[lean4]{extrakeywords={aesop cases add aesop? intro simp simp_all only split apply on_goal next rename_i safe unsafe norm constructors forward destruct norm_num done add_aesop_rules rfl subst ext}}
\newmintinline[lean]{lean4}{bgcolor={},ignorelexererrors=true}
\newminted[leancode]{lean4}{bgcolor={},ignorelexererrors=true,fontsize=\footnotesize,autogobble}
\BeforeBeginEnvironment{leancode}{\begin{tcolorbox}}
\AfterEndEnvironment{leancode}{\end{tcolorbox}}
\usemintedstyle{xcode}

\newcommand{\xcom}[1]{{\textcolor{cyan}{Xavier: #1}} }
\newcommand{\jcom}[1]{{\textcolor{orange}{Jannis: #1}} }

\newcommand{\Lam}[2]{\ensuremath{\lambda\, #1,\; #2}}
\newcommand{\All}[2]{\ensuremath{\forall\, #1,\; #2}}
\newcommand{\mvar}[1]{\ensuremath{?#1}}
\newcommand{\Prop}{\ensuremath{\mathrm{Prop}}}
\newcommand{\vars}{\ensuremath{\mathrm{vars}}}
\newcommand{\dom}{\ensuremath{\mathrm{dom}}}
\newcommand{\sub}{\ensuremath{\mathrm{sub}}}
\newcommand{\lvl}{\ensuremath{\mathrm{lvl}}}
\newcommand{\Rules}{\ensuremath{\mathcal{R}}}
\newcommand{\Hyps}{\ensuremath{\mathcal{H}}}
\newcommand{\States}{\ensuremath{\mathcal{S}}}
\newcommand{\CMatches}{\ensuremath{\mathcal{C}}}
\newcommand{\addHyp}{\ensuremath{\mathrm{addHyp}}}
\newcommand{\delHyp}{\ensuremath{\mathrm{delHyp}}}
\newcommand{\addMatch}{\ensuremath{\mathrm{addMatch}}}
\newcommand{\powerset}{\ensuremath{\mathbb{P}}}

\begin{document}

\title{Incremental Forward Reasoning for White-Box~Proof~Search}

%\titlerunning{Abbreviated paper title}
% If the paper title is too long for the running head, you can set
% an abbreviated paper title here

\author{Jannis Limperg\orcid{0000-0002-8861-5231} \and
  Xavier Généreux\orcid{0000-0003-4952-9557}}

\authorrunning{J.~Limperg and X.~Généreux}
\institute{Ludwig-Maximilians-Universität München, Munich, Germany\\
\email{\{jannis.limperg,xavier.genereux\}@lmu.de}}

\maketitle

\begin{abstract}
  Several proof assistants provide automation tactics based on tableau-style tree search, such as Isabelle's and Rocq's auto and Lean's Aesop.
  In this setting we consider \emph{forward rules}, which apply a given theorem, say, $A → B → C$, to any goal containing hypotheses $A$ and $B$, adding $C$ as a new hypothesis.
  When treated naively, such rules are tried on every goal encountered during the search, leading to repeated unifications of premises $A$ and $B$ with the hypotheses of each goal.
  We present an approach to forward rules that avoids some of this repeated work by taking advantage of similarities between successive goals.
  For each goal, we cache partial applications of forward rules in a custom data structure, the \emph{partial match state}, which enables efficient updates.
  Our technique is compatible with any search strategy and most logics.
  It has been implemented in Aesop.

  \keywords{Forward Reasoning \and Forward Chaining \and Tactics \and Interactive Theorem Proving.}
\end{abstract}

\section{Introduction}

In many proof assistants, simple automation tactics based on tableau-style tree search play a substantial role in practice: Isabelle's (TODO ref) and Rocq's (TODO ref) auto, ACL2's (TODO ref) waterfall, PVS's (TODO ref) grind, Lean's (TODO ref) Aesop (TODO ref), etc.
These tactics operate on \emph{goals} $Γ ⊢ A$, where the \emph{context} $Γ$ is a list of assumptions and $A$ is the proposition to be proved.
Faced with an initial goal, the tactics try various user-specified \emph{rules}, which correspond to admissible inferences in the prover's logic.
A successful rule reduces the current goal to zero or more subgoals, which are solved recursively until either a full proof is found or no rule applies to any open goal or the search times out.

Typical rules would be the $∧$-introduction lemma $A → B → A ∧ B$, which, when applied backwards, reduces a goal $Γ ⊢ A ∧ B$ to subgoals $Γ ⊢ A$ and $Γ ⊢ B$; or left $∨$-introduction, which reduces $Γ ⊢ A ∨ B$ to $Γ ⊢ A$.
Such \emph{backward rules} are the most common rule type, but most search tactics allow users to use any tactic as a rule.
These rule tactics can output arbitrary subgoals, subject only to the condition that proofs of the returned subgoals can be assembled into a proof of the goal on which the rule was run.

ACL2 and Aesop additionally provide special support for \emph{forward rules}.
Given, for example, the transitivity lemma $\All{x~y~z}{x < y → y < z → x < z}$, a forward rule run on the goal $a < b,\, b < c ⊢ A$ produces the single subgoal $a < b,\, b < c,\, a < c ⊢ A$.
Hence forward rules can be used to establish additional facts that may be relevant for other rules.
For example, the Aeneas project (TODO ref) uses Aesop's forward rules \jcom{(ensure that this is accurate)} in its proof automation to establish facts that are later used by an arithmetic decision procedure.

However, Aesop's (and ACL2's) support for forward rules was, until recently, quite basic.
In particular, each forward rule was tried on each goal separately (subject to pre-filtering by a discrimination tree (TODO ref) index).
This is wasteful since in practice, many rules produce subgoals with a similar---or even the same---context as the initial goal.
For example, the ∧-introduction rule affects only the goal's target, not its context.
Still, all forward rules applied to the initial $Γ ⊢ A ∧ B$ would be tried again on the subgoals $Γ ⊢ A$ and $Γ ⊢ B$, with predictably little effect.

In this paper, we present an alternative way to apply forward rules that addresses this issue.
The central idea is to remember, for each goal $Γ ⊢ A$, which forward rules can be partially applied to which sets of hypotheses.
When a non-forward rule then generates subgoals $Δ₁ ⊢ A₁$, \dots, $Δₙ ⊢ Aₙ$, the new contexts $Δᵢ$ are likely similar to $Γ$.
Hence it is generally cheaper (and often much cheaper) to start with the partial matches for $Γ$ and update them for each of the $Δᵢ$.
The update first deletes partial matches that include hypotheses no longer present in $Δᵢ$.
Afterwards it adds new partial matches for the hypotheses that are new in $Δᵢ$, extending the existing partial matches for a rule if the new hypothesis is compatible with them.
Whenever this process produces a full match---i.e., all premises of a forward rule are satisfied by a set of hypothesis in $Δᵢ$---the rule is applied and adds a corresponding new hypothesis to $Δᵢ$.
Our main contribution is a data structure, the \emph{partial match state}, that organises the partial matches in such a way that the update can be done efficiently.

In addition to this \emph{incrementality}, the partial match state satisfies two other desiderata:
\begin{itemize}
  \item It is \emph{persistent}, i.e.\ partial match states for parent and child goals share much of their structure.
        This is desirable since Aesop supports search strategies other than depth-first search and must therefore keep all goals encountered during the search, along with their partial match states, in memory.
  \item It reduces the number of \emph{unifications} performed when matching hypotheses against rule premises.
        In dependent type theory, unification happens up to definitional equality, which makes it quite expensive.
        We therefore want to avoid redundant unifications.
\end{itemize}

Our evaluation (Sec.~\ref{sec:evaluation}) shows that this new implementation of forward reasoning in Aesop substantially outperforms the previous, naive implementation on some (though not all) synthetic benchmarks.
The implementation, benchmarks and evaluation data are available in a supplement to this paper (TODO ref).
Mainline Aesop already uses the new implementation by default (TODO true?).

\section{Preliminaries}

We first introduce some terminology for matches and for forward rules (which we identify with their underlying lemmas).
Our foundation in this paper is dependent type theory, but our technique can be adapted to other logics.

Given a lemma $\All{(x₁ : A₁) \dots (xₙ : Aₙ)}{B}$, the $xᵢ$ are \emph{premises} and $B$ is the lemma's \emph{conclusion}.
The type $Aᵢ$ of the $i$-th premise may depend on (i.e., refer to) any premise $xⱼ$ with $j < i$.
Implication $A → B$ is an abbreviation for $\All{x : A}{B}$ where $B$ does not depend on $x$.
Propositions are (certain) types and we do not distinguish between the two concepts.

Premises on which a later premise depends are \emph{variables}.
All other premises are \emph{input premises}.
For example, the lemma $\All{x~y~z}{x < y → y < z → x < z}$ has variables $x, y, z$ and (unnamed) input premises of types $x < y$ and $y < z$.
If a variable occurs in at least two premises, like $y$ above, it is \emph{shared}.

For a lemma with $n$ input premises, we assign to each input premise a unique number between $1$ and $n$.
This is the premise's \emph{slot}, which we often identify with the premise itself.
For now, we assume that the input premises are numbered consecutively, so in the above example slot 1 has type $x < y$ and slot 2 has type $y < z$.
The \emph{shared variables of slot $i$}, $\vars(i)$ are those variables that appear in the type of $i$ and also in at least one type of a slot $j < i$.

If $h : A$ is a hypothesis in the context of a goal and $A$ unifies with the type $B$ of slot $i$, we say that $h$ \emph{matches} $i$.
Unification induces a substitution $σ$ such that $A[σ]$ is definitionally equal to $B[σ]$; we call this substitution $\sub_{i}(h)$.
For now we do not specify exactly what \enquote{unifies} means; see Sec.~\ref{sec:implementation}.

A \textit{match} $M$ for a given rule $r$ is a partial map from slots of $r$ to hypotheses.
The map must satisfy the following conditions:
\begin{enumerate}
  \item\label{cond:match:matches} For each slot $i ∈ \dom(M)$, the hypothesis $M(i)$ matches $i$.
  \item\label{cond:match:compat} For all slots $i,j ∈ \dom(M)$, the substitutions $\sub_{i}(M(i))$ and $\sub_{j}(M(j))$ are \emph{compatible}.
        This means that for each variable $x ∈ \dom(\sub_{i}(M(i))) ∩ \dom(\sub_{j}(M(j)))$ we have $\sub_{i}(M(i))(x) = \sub_{j}(M(j))(x)$, i.e.\ the substitutions agree on all common variables.
  \item\label{cond:match:closed} $M$ is \emph{downward-closed}: if $i ∈ \dom(M)$, then for any slot $j < i$ of $r$ we also have $j ∈ \dom(M)$.
\end{enumerate}
The \emph{substitution of a match $M$}, $\sub(M)$, is the union of the substitutions induced by the hypotheses in $M$, i.e. $\sub(M) ≔ ⋃_{i ∈ \dom(M)}\sub_{i}(M(i))$.
This is well-defined by requirement~\ref{cond:match:compat}.
The \textit{level of a match $M$}, $\lvl(M)$, is the maximal $i$ such that $i ∈ \dom(M)$.
A match for rule $r$ is \textit{complete} if $i ∈ \dom(M)$ for every slot $i$ of $r$, and \emph{partial} otherwise.

A partial match $M$ for rule $r$ corresponds to a partial application of the rule to the terms given in $\sub(M)$.
The application is type-correct by requirements~\ref{cond:match:matches} and~\ref{cond:match:compat}.
If $M$ is complete, then $\sub(M)$ contains a term for every slot and every variable---hence for every premise---of $r$ and we have a full application.

Requirement~\ref{cond:match:closed} implies that we will be adding hypotheses to matches in the order in which the slots appear.
Hence for a rule $r : A → B → C → D$, we effectively consider partial applications $r~a$ and $r~a~b$ for some $a : A$ and $b : B$, but not $r~\text{--}~b$.
This prevents us from constructing $r~a~b$ in two different but ultimately redundant ways.
The term orders used in various saturation calculi serve a similar function.

\section{Naive Forward Reasoning}

Prior to this work, Aesop used what we call naive forward reasoning (TODO ref).
This approach treats a forward rule essentially like any other Aesop rule.
Hence, given a goal $h₁ : T₁,\, \dots, hₙ : Tₙ ⊢ U$, we first query an index to determine which rules might apply to the goal.
For forward rules, this index stores the type of the last premise (since later premises tend to be more specific).
The index is queried for each $Tᵢ$, yielding a set of rules that have a premise which likely unifies with at least one hypothesis.
Of these rules and any non-forward rules selected in a similar way, we select the highest-priority one.

If the selected rule is a forward rule $r : \All{(x₁ : A₁) \dots (xₘ : Aₘ)}{B}$, we first unify $Aₘ$ with one of the candidate hypotheses determined by the index.
If successful, this results in a substitution $σ$ whose domain contains $xₘ$ and any variables occurring in $Aₘ$.
We then proceed to unify $A_{m-1}[σ]$ with the type of each hypothesis in the context, etc., until we have found a complete match for $r$ (skipping premises already determined by $σ$).
If a premise type $A_{i}[σ]$ does not unify with any hypothesis type, we backtrack and consider other potential matching hypotheses for $A_{i+1}$.
This may lead to a different substitution $τ$ and therefore to matching hypotheses for $A_{i}[τ]$.

If this process yields one or more full applications $r~a₁ \dots aₘ$, we add $B[x₁ ↦ a₁, \dots, xₘ ↦ aₘ]$ as a new hypothesis unless a hypothesis of this type is already present in the context.

\jcom{Add example?}

This approach is efficient when the last premise of a rule is not present in the context since the rule is then never run.
If the last premise is present, however, we perform a large number of unifications between premises and hypotheses.
Furthermore, these unifications are repeated when we proceed to another goal with a similar context.
In particular, the contexts of subgoals produced by whatever rule is eventually applied to the current goal are likely to be substantially similar, if not identical, to the current context, but these similarities are not exploited since the naive algorithm is stateless.

\jcom{Mention fast subsumption paper?}

\section{Incremental Forward Reasoning}%
\label{sec:incremental}

With the weaknesses of the naive approach in mind, we introduce an incremental, stateful solution to the problem of finding complete matches.
The main idea is to store, for each goal $Γ ⊢ A$, the partial matches implied by the hypotheses in $Γ$, and to reuse these partial matches for subgoals $Δ ⊢ B$.
This rests on the assumption that $Δ$ is likely similar to $Γ$ in practice, and that it is therefore cheaper to update the partial matches for $Γ$ to obtain those of $Δ$ than to compute those of $Δ$ from scratch.
Our main contribution is a data structure, the \emph{partial match state}, that allows us to perform these updates efficiently.

\paragraph{Partial Match State.}
We associate to each goal in Aesop's search tree a partial match state that reflects the goal's context.
Let $\States$ be the set of partial match states, $\Hyps$ the set of hypotheses, $\Rules$ the set of rules, $\CMatches$ the set of complete matches and $\powerset(X)$ the powerset of $X$.
The partial match state's interface then consists of two functions
\begin{equation*}
  \addHyp : \States → \Hyps → \States × \powerset(\Rules × \CMatches) \qquad \delHyp : \States → \Hyps → \States
\end{equation*}
The $\addHyp$ function adds a hypothesis to the partial match state.
Hence, if $s$ is the partial match state corresponding to context $Γ$ and $\addHyp(s, h : T) = (s', M)$, then $s'$ is the partial match state corresponding to $Γ,\, h : T$.
Similarly, if $s$ is the partial match state corresponding to $Γ, h : T$, then $\delHyp(s, h : T)$ is the partial match state corresponding to $Γ$.
The second output of $\addHyp$, $M$, is a set of pairs $(r, m)$ where $r$ is a rule and $m$ is a complete match for $r$.
These are the matches that were completed by adding $h : T$.

When Aesop is run on an initial goal with context $h₁ : T₁, \dots, hₙ : Tₙ$, the partial match state for it is built by starting with an empty state and applying $\addHyp$ to each hypothesis $hᵢ$.
Afterwards, whenever an Aesop rule is run on a goal with context $Γ$, producing subgoals with contexts $Δ₁, \dots, Δₙ$, we derive the partial match state for each subgoal context $Δⱼ$ from the partial match state for $Γ$, in two steps:
\begin{enumerate}
  \item Apply $\delHyp$ once for each hypothesis that was deleted, i.e.\ that appears in $Γ$ but not in $Δⱼ$.
  \item Apply $\addHyp$ once for each hypothesis that was added, i.e.\ that appears in $Δⱼ$ but not in $Γ$.
\end{enumerate}
Changes to a hypothesis (e.g.\ a change of its type) are treated as a deletion followed by an addition.

\paragraph{Rule State.}
Partial matches are specific to each rule, so the partial match state naturally decomposes into a set of \emph{rule states}, one per rule.
Given a goal $Γ ⊢ A$ and a rule $r$, the rule state for $r$ contains exactly the partial matches of $r$ in context $Γ$.
A rule state supports $\addHyp$ and $\delHyp$ methods analogous to those on partial match states.
Adding a hypothesis to a partial match state then amounts to adding it to each rule state (which may yield new complete matches for the rule); deleting a hypothesis amounts to deleting it from each rule state.
We initially focus on how to add hypotheses, since this question motivates much of the design of the rule state data structure.

When a hypothesis is added to a rule state, two things can happen.
First, the hypothesis may allow us to extend partial matches already present in the state.
For instance, consider the rule $r : \All{x}{P~x → Q~x → R~x → S~x}$ and a rule state containing the partial match $\{1 ↦ h₁\}$, with $1$ referring to the slot of type $P~x$ and $h₁ : P~a$ for some $a$.
Adding a new hypothesis $h₂ : Q~a$ to this rule state means that we should add to the state the extended match $\{1 ↦ h₁, 2 ↦ h₂\}$.

Second, adding a match may trigger the insertion of further matches.
Suppose that before adding $h₁$ and $h₂$, we had already added a hypothesis $h₀ : R~a$ to the rule state.
Once the partial match $\{1 ↦ h₁, 2 ↦ h₂\}$ arrives, we should recognise that it can be extended with $h₀$ to obtain the (complete) match $\{1 ↦ h₁, 2 ↦ h₂, 3 ↦ h₀\}$.

\paragraph{Variable Indices.}
Extending the matches above was possible only because all hypotheses are compatible on the shared variable $x$, i.e.\ they all instantiate $x$ with the same term $a$.
In general, to extend a match $M$ with a hypothesis $h : T$ at slot $i$, we need to ensure that the substitution of $M$, $\sub(M)$, is compatible with the substitution of $h$, $\sub_{i}(h)$.

The rule state therefore uses two \emph{variable indices} $H$ and $M$ to index hypotheses and matches by their instantiations for shared variables, allowing us to quickly determine compatible pairs of matches and hypotheses.
We could use a substitution tree (TODO ref, confirm) for this, but our custom data structure is simpler and perhaps more efficient.
The \emph{hypothesis index} $H$ maps each triple $(x, i, t)$ (where $i > 1$ is a slot, $x ∈ \vars(i)$ a variable and $t$ a term) to the set of hypotheses $h$ added to the rule state such that $h$ matches $i$ and $\sub_{i}(h)(x) = t$.
In other words, $H$ indexes the known hypotheses by the slots they match and the instantiations of shared variables.
Note that hypotheses matching slot $1$ are not stored since they can never extend a match.

Similarly, the \emph{match index} $M$ maps each triple $(x, i, t)$ to the set of partial matches $m$ (that can be derived from the hypotheses added to the rule state) such that $i = \lvl(m) $, $x ∈ \vars(i + 1)$ and $\sub(m)(x) = t$.
Matches for the maximal slot are not stored because, being complete, they never need to be extended.

Given a hypothesis $h : T$ that matches slot $i > 1$ with substitution $σ = \sub_{i}(h)$, the partial matches that can be extended by $h$ are those in slot $i - 1$ whose substitutions are compatible with $σ$ on the variables $\vars(i)$ (i.e., the variables shared between $i$ and any earlier slot).
Assuming for the moment that $\vars(i)$ is nonempty for all slots $i > 1$, these matches are
\[
  \bigcap_{x \in \vars(i)} M(x, i-1, σ(x))
\]
Similarly, given a partial match $m$ at level $i$ with substitution $σ = \sub(m)$, the hypotheses that could extend $m$ are
\[
  \bigcap_{x \in \vars(i+1)} H(x, i+1, σ(x))
\]
The number of shared variables tends to be small in practice, so these intersections can be computed efficiently.

From these observations we can directly derive two procedures for adding hypotheses and matches  to the rule state.
The procedures maintain the invariants of the variable indices while reporting any complete matches discovered during this process.

\begin{algorithm}
  \SetKwInOut{Precondition}{Precondition}
  \SetKwInOut{Postcondition}{Postcondition}
  \Precondition{$H$ and $M$ contain the hypotheses and matches corresponding to a context $Γ$}
  \Input{A hypothesis $h : T$ matching slot $i$ of $r$ with substitution $σ$}
  \Output{Complete matches of $r$ in context $Γ,\, h : T$ that contain $h$}
  \Postcondition{$H$ and $M$ contain the hypotheses and matches corresponding to $Γ,\, h : T$}
  \BlankLine
  \Procedure{$\mathrm{addHyp}(h : T)$}{
    \eIf{$i = 1$}{
      $\mathrm{addMatch}(\{1 ↦ h\})$
    }{
      \For{$x$ \KwIn $\vars(i)$}{
        Insert $h$ into the set $H(x, i, σ(h))$
      }
      \KwLet $\mathit{ms} ≔ \bigcap_{x \in \vars(i)} M(x, i-1, σ(x))$ \\
      $\mathit{completeMs} \gets ∅$ \\
      \For{$m$ \KwIn $\mathit{ms}$}{
        $\mathit{completeMs} \gets \mathit{completeMs} ∪ \mathrm{addMatch}(m ∪ \{i ↦ h\})$
      }
      \Return{$\mathit{completeMs}$}
    }
  }
  \BlankLine % without these, the caption is not offset properly
  \BlankLine
  \caption{Adding a hypothesis to the rule state for a rule $r$}%
  \label{alg:addhyp}
\end{algorithm}

The rule state's $\addHyp$ method (Algorithm~\ref{alg:addhyp}) adds a hypothesis $h : T$ matching slot $i$ to the rule state.
(If a hypothesis matches multiple slots, $\addHyp$ is called multiple times.)
For $i = 1$, we add the singleton match $\{1 ↦ h\}$ to the rule state.
For $i > 1$, we first insert $h$ into the hypothesis index $H$.
Then we query the match index $M$ for matches that can be extended by $h$ and add the extended matches to the rule state.
While adding matches, we may discover new complete matches, which are collected and returned.

% TODO pre- and postcondition?
\begin{algorithm}
  \Input{A partial match $m$ of $r$ at level $i$ with substitution $σ$}
  \Output{A set of complete matches of $r$}
  \BlankLine
  \Procedure{$\mathrm{addMatch}(h : T)$}{
    \eIf{$i$ is complete}{
      \Return{$\{m\}$}
    }{
      \For{$x$ \KwIn $\vars(i + 1)$}{
        Insert $m$ into the set $M(x, i, σ(x))$
      }
      \KwLet $\mathit{hs} ≔ \bigcap_{x \in \vars(i + 1)} H(x, i + 1, σ(x))$ \\
      $\mathit{completeMs} \gets ∅$ \\
      \For{$h$ \KwIn $\mathit{hs}$}{
        $\mathit{completeMs} \gets \mathit{completeMs} ∪ \mathrm{addMatch}(m ∪ \{i + 1 ↦ h\})$
      }
      \Return{$\mathit{completeMs}$}
    }
  }
  \BlankLine % without these, the caption is not offset properly
  \BlankLine
  \caption{Adding a match to the rule state for a rule $r$}%
  \label{alg:addmatch}
\end{algorithm}

The rule state's $\addMatch$ method (Algorithm~\ref{alg:addmatch}) adds a match $m$ with level $i = \lvl(m)$ to the rule state.
If $m$ is already complete, it is returned.
Otherwise $m$ is inserted into $M$ and we query $H$ for hypotheses that can extend $m$.
Any extended matches thus produced are added to the rule state recursively.

\paragraph{Variable Clusters.}
We have so far assumed that for each slot $i > 1$, the set of shared variables $\vars(i)$ is nonempty, i.e.\ each slot shares at least one variable with at least one of the previous slots.
This assumption is violated for rules such as $\All{x~y}{P~x → Q~y → R~x~y}$: slot 2 ($Q~y$) shares no variables with slot 1 ($P~x$).
As a result, our above algorithms fail.
Suppose we are adding the hypothesis $h₂ : Q~b$, having already added the hypothesis $h₁ : P~a$ and hence the partial match $\{1 ↦ h₁\}$.
The set of matches compatible with $h₂$ is supposedly $\bigcap_{x \in \vars(2)} M(x, i-1, σ(x)) = ∅$, but in fact the match $\{1 ↦ h₁\}$ can be extended with $h₂$.
In fact, any match at level 1 can be extended with any hypothesis matching slot 2 since the two slots are independent.

To account for this fact, we partition the set of premises of each rule into maximal subsets of premises connected by shared variables, using a construction from (TODO ref).
These subsets, called \emph{variable clusters}, share no variables with each other, so each can be treated as a separate rule with its own rule state.
Finding a complete match for a rule amounts to finding one complete match for each of its clusters.
The slots within each cluster can be ordered to ensure that each slot shares at least one variable with the previous slots, satisfying our assumption.

\paragraph{Deletion.}
When a hypothesis $h$ is removed from a goal's context, we must update the partial match state accordingly.
This means deleting $h$ from any rule state to which it was previously added, i.e.\ from any rule state for a rule $r$ with a slot $i$ matching $h$.
To facilitate deletion, we cache this information when $h$ is added to the rule state.
When $h$ is deleted, we can then efficiently determine the relevant rule states and delete $h$ from the hypothesis index $H$ at slot $i$ and from the match index $M$ at all slots $j ≥ i$.

\paragraph{Example 1.}
As a first example, consider a rule state for the transitivity rule $r : \All{x~y~z}{x ≤ y → y ≤ z → x ≤ z}$ to which we add, in order, the hypotheses
$h₁ : 301 ≤ 302$ and $h₂ : 300 ≤ 301$.
The rule has two slots of types $x ≤ y$ and $y ≤ z$ which share the variable $y$.

The hypothesis $h₁ : 301 ≤ 302$ unifies with both slots, so we run Algorithm~\ref{alg:addhyp} twice.
For slot 1, unification yields the substitution $\{x ↦ 301, y ↦ 302\}$.
Since this is the first slot, we start a new partial match $\{1 ↦ h₁\}$, which Algorithm~\ref{alg:addmatch} inserts into the set $M(y, 1, 302)$.
This match cannot be extended since the hypothesis index $H$ does not contain a hypothesis for slot 2.

For slot 2, unification yields the substitution $σ ≔ \{y ↦ 301, z ↦ 302\}$, so we insert $h₁$ into $H(2, y, 301)$.
No matches at level 1 can be extended by $h₁$ since
\[
  \bigcap_{x \in \vars(2)} M(x, 1, σ(x)) = M(y, 1, 301) = \emptyset
\]
At this point, $H$ and $M$ are in the following state.
For brevity, we write matches $\{1 ↦ h₁, \dots, n ↦ hₙ\}$ as $[h₁, \dots, hₙ]$.
We also write $H_{y}$ instead of $H(y, \text{--}, \text{--})$, and similar for $M$.
\begin{center}
\begin{tikzpicture}[outer sep=auto, level distance=12mm, scale=0.50]
  \node[xshift = 0] {$H_{y}$}
    child {node {2}
      child {node {$301$}
        child {node {$\{h₁\}$}}}
    %  child {node {$300$}
    %    child {node {$\{\}$}}}
    };
  \node[xshift=160] {$M_y$}
    child {node {1}
      child {node {$302$}
        child {node {$\{[h₁]\}$}}}
    %  child {node {$301$}
    %    child {node {$\{\}$}}}
    };
    %child {node[xshift=20] {2}
    %  child {node {$301$}
    %    child {node[yshift=-2em] {$\{\}$}}}};
\end{tikzpicture}
\end{center}

Now we add $h₂ : 300 ≤ 301$, which again unifies with both slots.
For slot 1, $\sub₁(h₂)(y) = 301$, so we add the match $\{1 ↦ h₂\}$ to $M(y, 1, 301)$.
We then check for hypotheses in slot 2 that also instantiate $y$ with $301$, and indeed we find $M(2, y, 301) = \{h₁\}$.
Hence we return the complete match $\{1 ↦ h₂, 2 ↦ h₁\}$, which induces a new hypothesis $h₃ : 300 ≤ 302$ to be added later.

For slot 2, we add $h₂$ to $H(y, 2, 300)$.
There are no compatible matches at level 1, so we are done with $h₂$, yielding the following final rule state.
\begin{center}
    \begin{tikzpicture}[outer sep=auto, level distance=12mm, scale=0.50]
      \node[xshift = 0] {$H_y$}
        child {node {2}
          child {node {$301$}
            child {node {$\{h₁\}$}}}
          child {node {$300$}
            child {node {$\{h₂\}$}}}
        };
      \node[xshift=160] {$M_y$}
        child {node {1}
          child[xshift=-20] {node {$302$}
            child {node {$\{[h₁]\}$}}}
          child[xshift=20] {node {$301$}
            child {node {$\{[h₂]\}$}}}
        };
    \end{tikzpicture}
    \end{center}

\paragraph{Example 2.}
We now consider a rule $s : \All{x~y}{A~x~y → B~x~y → C~x~y}$ with multiple shared variables.
We add hypotheses $h₁ : B~a~a$, $h₂ : A~a~b$ and $h₃ : B~a~b$ to the rule state of $s$, starting with $h₁$:
% NOTE : remove comments to get full trees.
\begin{center}
  \begin{tikzpicture}[level distance=12mm, scale=0.50]
    \node[xshift = 30] {$H_x$}
        %child[xshift = -20] {node {1}
        %  child {node {$a$}
        %    child {node {$\{ \}$}}}
        %  child {node {$b$}
        %    child {node {$\{ \}$}}}}
        child {node {2}
        child {node {$a$}
            child {node {$\{h_1\}$}}}
        % child {node {$b$}
        %    child {node {$\{ \}$}}}
        };
    \node[xshift = 110] {$H_y$}
        %child[xshift = -20] {node {1}
        %    child {node {$a$}
        %        child {node {$\{ \}$}}}
        %    child {node {$b$}
        %        child {node {$\{ \}$}}}}
        child {node {2}
            child {node {$a$}
                child {node {$\{h_1\}$}}}
        %    child {node {$b$}
        %        child {node {$\{ \}$}}}
        };
    \node[xshift = 190] {$M_x$};
        %child[xshift = -20] {node {1}
        %    child {node {$a$}
        %        child {node {$\{ \}$}}}
        %    child {node {$b$}
        %        child {node {$\{ \}$}}}}
        %child[xshift = 20] {node {2}
        %    child {node {$a$}
        %        child {node {$\{\}$}}}
        %    child {node {$b$}
        %        child {node {$\{ \}$}}}
        %};
    \node[xshift = 270] {$M_y$};
        %child[xshift = -20] {node {1}
        %    child {node {$a$}
        %        child {node {$\{ \}$}}}
        %    child {node {$b$}
        %        child {node {$\{ \}$}}}}
        %child[xshift = 20] {node {2}
        %    child {node {$a$}
        %        child {node {$\{\}$}}}
        %    child {node {$b$}
        %        child {node {$\{ \}$}}}
        %};
  \end{tikzpicture}
\end{center}
At this point there are no matches, so there is nothing to extend.
We now add $h_2 : A~a~b$, which initially generates a match $m = \{1 ↦ h₂\}$ that is added to $M$:
% NOTE : uncomment to get full trees.
\begin{center}
  \begin{tikzpicture}[outer sep=auto, level distance=12mm, scale=0.50]
    \node[xshift = 0] {$H_x$}
        child {node {2}
            child {node {$a$}
                child {node {$\{h_1\}$}}}
            %child {node {$b$}
            %    child {node {$\{ \}$}}}
            };
    \node[xshift = 80] {$H_y$}
        child {node {2}
            child {node {$a$}
                child {node {$\{h_1\}$}}}
            %child {node {$b$}
            %    child {node {$\{ \}$}}}
                };
    \node[xshift = 160, yshift = 0] {$M_x$}
        child {node {1}
            child {node {$a$}
                child {node {$\{[h_2]\}$}}}
            %child {node {$b$}
            %   child {node {$\{ \}$}}}
                };
        %child[xshift = 20] {node {2}
        %    child {node {$a$}
        %        child {node {$\{\}$}}}
        %    child {node {$b$}
        %        child {node {$\{ \}$}}}
        %};
    \node[xshift = 240, yshift = 0] {$M_y$}
        child {node {1}
        %    child {node {$a$}
        %        child {node {$\{ \}$}}}
            child {node {$b$}
                child {node {$\{[h_2]\}$}}}
        };
        %child[xshift = 20] {node {2}
        %    child {node {$a$}
        %        child {node {$\{\}$}}}
        %    child {node {$b$}
        %        child {node {$\{ \}$}}}
        %};
  \end{tikzpicture}
\end{center}
To find hypotheses compatible with $m$, we consider the set of variables $\vars(\lvl(m) + 1)$.
These are the variables shared between slot $\lvl(m) + 1 = 2$ and all previous slots, i.e.\ $x$ and $y$.
Hence the compatible hypotheses are
\[
  \bigcap_{x \in \vars(\lvl(m) + 1)} H(x, i + 1, \sub(m)(x)) = H(x, 2, a) \cap H(y, 2, b) = \emptyset
\]
This means the match cannot currently be extended.
We now turn to the remaining hypothesis $h_3 : B~a~b$, adding it first to $H$:
\begin{center}
  \begin{tikzpicture}[outer sep=auto, level distance=12mm, scale=0.50]
    \node[xshift = 0] {$H_x$}
      child {node {2}
          child {node {$a$}
              child {node {$\{h_1, h_3\}$}}}
          %child {node {$b$}
          %    child {node {$\{ \}$}}}
          };
    \node[xshift = 80] {$H_y$}
      child {node {2}
          child {node {$a$}
              child {node {$\{h_1\}$}}}
          child {node {$b$}
              child {node {$\{h_3\}$}}}};
    \node[xshift = 160, yshift = 0] {$M_x$}
      child {node {1}
          child {node {$a$}
              child {node {$\{[h_2]\}$}}}
          %child {node {$b$}
          %   child {node {$\{ \}$}}}
              };
    \node[xshift = 240, yshift = 0] {$M_y$}
      child {node {1}
      %    child {node {$a$}
      %        child {node {$\{ \}$}}}
          child {node {$b$}
              child {node {$\{[h_2]\}$}}}
      };
  \end{tikzpicture}
\end{center}
Since $h₃$ matches slot $i = 2$, the matches that can be extended by $h₃$ are
\[
  \bigcap_{x \in \vars(i)} M(x, i - 1, \sub_{i}(x)) = M(x, 1, a) \cap M(y, 1, b) = \{[h₂]\}
\]
We have found the complete match $[h₂, h₃]$ and can add a new hypothesis of type $C~a~b$.

\section{Implementation}%
\label{sec:implementation}

Implementing the preceding technique efficiently requires some care, particularly in the context of dependent type theory.
We briefly discuss the most prominent challenges.

\paragraph{Unification.}
In Lean's type theory, types contain programs and unification is expected to respect definitional equality, i.e.\ equality up to evaluation.
For instance, a theorem with premise $P~2$, where $P$ is some predicate, should apply to a hypothesis of type $P~((\Lam{x}{x})~2)$ since the two types are definitionally equal.
As a result, unifying premises and hypotheses is arbitrarily expensive in theory and a major cost centre in practice.
Our technique therefore seeks to minimise the number of unifications performed.

To limit the expense of unification, we perform unification at \emph{reducible} transparency.
Lean has multiple transparency levels that determine which constants are unfolded.
\enquote{Reducible} is the most restrictive of these, so we unfold few (and, in practice, only non-recursive) definitions, which greatly reduces the cost of unification.
However, this limits the power of forward reasoning since fewer terms can be unified.

We also need to account for higher-order unification problems: $Q~\mvar{f}$, where $Q$ is a predicate over functions and $\mvar{f}$ is a function variable, should unify with $Q~(\Lam{x}{x})$.
Since higher-order unification is undecidable and does not admit most general unifiers (TODO ref), we instead use a unification algorithm provided by Lean that is complete for first-order unification problems and heuristically solves some higher-order problems as well.
This makes our technique incomplete in the sense that some theorem instantiations will be missed, but since the same unification algorithm is used throughout Lean, users are well acquainted with this form of incompleteness.

During unification, we treat metavariables in hypotheses as constants, i.e.\ we never assign them.
This reflects the expected behaviour of forward rules: given a hypothesis $\mvar{x} < \mvar{y}$, we would not expect a forward rule to commit to the choice $\mvar{x} ≔ 1$ and $\mvar{y} ≔ 0$ just because this allows the rule to derive a contradiction.

\paragraph{Data Representation.}
Since the hypothesis index $H$ and the variable index $M$ of a rule state have the same domain, we combine them into one map.
This core data structure is then represented by nested persistent hash maps: a first hash map maps variables to a second hash map; the second hash map maps slots to a third hash map; and the third hash map maps instantiations to sets of hypotheses and sets of partial matches.

When we compare instantiations, the comparison should be up to definitional equality.
For example, when we try to apply a theorem $\All{x}{P~x → Q~x → R~x}$ where the first slot matches a hypothesis of type $P~a$ and the second slot matches a hypothesis of type $P~((\Lam{x}{x})~a)$, the application should succeed even though the instantiations of $\mvar{x}$ are different.
We therefore do not store $a$ and $(\Lam{x}{x})~a$ in the variable maps as-is.

Instead, we bring all instantiations into a normal form which we call \emph{reducible proof-irrelevant normal form} (RPINF).
This is the usual normal form of expressions with respect to Lean's notion of computation, with two modifications.
First, only \emph{reducible} defined constants are unfolded.
This reflects our choice to perform unification at reducible transparency.
Second, parts of the original expression that are proofs (in the sense that their types are members of the universe $\Prop$ of propositions) are not normalised.
This reflects the fact that Lean's type theory definitionally equates any two proofs of the same proposition, so there is no need to check whether they are equal.
When computing the RPINF, we also mark all proofs occurring in it with some special \enquote{metadata}.

With this setup, two expressions $t$ and $u$ are definitionally equal at reducible transparency if and only if their RPINFs, $t'$ and $u'$, are syntactically equal except for those portions of $t'$ and $u'$ that are proofs, which are always considered equal.
Since this is an entirely syntactic notion of equality, it can be checked quickly and we can define an effective hash function that is compatible with it.
This allows us to use a hash map for the instantiations while still comparing them up to definitional equality.

We believe that this scheme is more efficient than alternative schemes relying on repeated unification.
For example, we could use Lean's implementation of imperfect discrimination trees (TODO ref), which implement a map from expressions to arbitrary data where lookup respects definitional equality.
However, since these discrimination trees are imperfect, they may return spurious lookup results, so whether a lookup result is valid must be verified by unifying the query expression with the expression that was originally stored in the discrimination tree.
We believe that repeatedly performing such unifications would generally be more expensive than calculating the RPINF of each hypothesis type (which can be cached).

\paragraph{Indexing.}
When adding a hypothesis $h : T$ to the partial match state, we add it to the rule state of each rule $r$ such that $h$ matches a slot of $r$.
To optimise this operation, we use an imperfect discrimination tree index that, for each rule $r$ with slot $i$ corresponding to a premise of type $Tᵢ$, maps the type $Tᵢ$ to the pair $(r, i)$.
Querying this index for $T$ quickly determines all rules and slots for which $h$ is likely relevant.

\paragraph{Match Equivalence.}
Naively, two matches $\{1 ↦ h₁, \dots, n ↦ hₙ\}$ and $\{1 ↦ h₁', \dots, n ↦ hₙ'\}$ would be considered equal if they are structurally equal, i.e.\ $h₁ = h₁'$, \dots, $hₙ = hₙ'$.
However, consider the rule $r : \All{x~y}{P~x~y → Q~x~z → R~x}$ and the hypotheses $h₁ : P~a~b$, $h₂ : P~a~c$, $h₃ : Q~a~d$ and $h₄ : Q~a~e$.
The complete matches $m₁ ≔ \{1 ↦ h₁, 2 ↦ h₃\}$ and $m₁' ≔ \{1 ↦ h₁, 2 ↦ h₄\}$ are structurally different, but the difference does not matter because the applications $r~h₁~h₃$ and $r~h₁~h₄$ both have type $R~a$.
Generating both $m₁$ and $m₁'$ would therefore be redundant.
Similarly, the partial matches $m₂ ≔ \{1 ↦ h₁\}$ and $m₂' ≔ \{1 ↦ h₂\}$ are redundant because the choice between $h₁$ and $h₂$ affects neither the type of any eventual application derived from $m₂$ and $m₂'$ nor the hypotheses that can be used to complete $m₂$ and $m₂'$.
Hence we should store only one of $m₂$ and $m₂'$ in the rule state of $r$.
Based on these observations, we consider two matches $m$ and $m'$ of a rule $r$ with conclusion $A$ equal if $\lvl(m) = \lvl(m')$ and for each variable $x$ that appears either in the conclusion of $r$ or in the type of a slot $i$ of $r$ with $i > \lvl(m)$ we have $\sub(m)(x) = \sub(m')(x)$.
To ensure that we respect definitional equality, the instantiations in the substitutions are kept in RPINF.

\paragraph{Redundant Hypotheses.}
When we find a complete match, we add a new hypothesis of the corresponding type $T$ to the goal, but only if there is no other hypothesis of type $T$ already present.
To efficiently implement this check, we store in the forward match state a set containing the RPINFs of all hypotheses that have been added to (and not subsequently removed from) the state.
We modified the naive forward reasoning implementation to use the same mechanism.

\section{Evaluation}%
\label{sec:evaluation}

There are unfortunately no standard benchmarks for Aesop-like tactics, and since Aesop is not expected to solve most goals without an extensive, manually curated set of rules, benchmarks for push-button theorem provers such as TPTP (TODO ref) are not very meaningful.
At the same time, forward rules are currently little used by Aesop's main client, the Mathlib mathematics library (TODO ref).
We therefore evaluate our technique against the previous, naive Aesop implementation on several synthetic benchmarks that showcase the performance characteristics of incremental forward reasoning.

For each benchmark, we set up certain forward rules and a goal with certain hypotheses.
We then run the \texttt{saturate} tactic, which uses either naive or incremental forward reasoning to exhaustively apply the forward rules.
Performing only forward reasoning is the best-case scenario for the incremental algorithm since previous results can be fully reused.
When forward reasoning is combined with other rules, we would expect smaller gains, depending on how much reuse the non-forward rules allow.

Benchmark code and data are available in our supplement (TODO ref).
The results shown below were obtain on a Macbook Pro with an Apple~M2 Pro processor and \SI{32}{GB} of RAM, averaging over \textcolor{red}{N} (TODO) runs per benchmark.

\paragraph{Transitivity.}
Our first benchmark is a scaled-up variant of the transitivity example from Sec.~\ref{sec:incremental}.
Given some relation $≺$ on natural numbers, we register the lemma $\All{x~y}{x ≺ y → y ≺ z → x ≺ z}$ as the sole forward rule and set up a goal with hypotheses $h₁ : a ≺ a + 1, \dots, hₙ : a + n - 1 ≺ a + n$ (TODO what is $a$?).
Saturating this goal adds $n(n-1)/2$ hypotheses to the context.

Instead of the natural number type of Lean's standard library, which has special support in the compiler and kernel, we use a custom type of Peano naturals.
Unifying two concrete Peano natural numbers $n$ and $m$ involves comparing $\min(n, m)$ constructors.
We can therefore use moderately large numbers to simulate the bigger unification problems that Aesop encounters, for example, in Mathlib's category theory development.

\begin{figure}
  \centering
  \begin{subfigure}{.5\textwidth}
    \centering
    \begin{tikzpicture}[scale=0.75]
      \begin{axis}[
        xlabel={Number of hypotheses},
        ylabel={Time in ms},
        xmin=1, xmax=16,
        ymin=2^3, ymax=2^13,
        xtick={1,2,4,8,16},
        ytick={2^3,2^5,2^7,2^9,2^11,2^13},
        xmode=log,
        ymode=log,
        log basis x=2,
        log basis y=2,
        legend pos=north west,
        ymajorgrids=true,
        grid style=dashed,
        legend image post style={mark=},
        ]
        \addplot[
          color=orange,
          mark=square,
          ]
          coordinates {
            (1, 7.663472) (2, 9.354750) (4, 15.768194) (8, 104.921791) (16, 1882.683111)
          };
        \addlegendentry{naive}
        \addplot[
          color=blue,
          mark=square,
          ]
          coordinates {
            (1, 10.308541) (2, 10.704638) (4, 16.274305) (8, 38.800833) (16, 179.697681)
          };
        \addlegendentry{incremental}
        \addplot[
          color=orange,
          mark=o,
          ]
          coordinates {
            (1, 10.591138) (2, 23.881333) (4, 142.013389) (8, 1676.148375) (16, 24327.359417)
          };
        \addplot[
          color=blue,
          mark=o,
          ]
          coordinates {
            (1, 13.974694) (2, 26.216833) (4, 68.953444) (8, 245.601028) (16, 1028.670680)
          };
      \end{axis}
    \end{tikzpicture}
    \caption{Transitivity benchmark}
    \label{fig:trans}
  \end{subfigure}%
  \begin{subfigure}{.5\textwidth}
    \centering
    \begin{tikzpicture}[scale=0.75]
      \begin{axis}[
        xlabel={Number of Rules},
        %ylabel={Time in ms},
        xmin=1, xmax=32,
        ymin=2^3, ymax=1700,
        ymode=log,xmode=log,
        log basis x=2,
        log basis y=2,
        legend pos=north west,
        ymajorgrids=true,
        grid style=dashed,
        legend image post style={mark=},
        ]

        \addplot[
          color=orange,
          mark=square,
          ]
          coordinates {
            (1, 10.399958) (2, 16.426541) (4, 43.461403) (8, 205.595541) (16, 1238.090889) (32, 8927.857819)
          };
        \addlegendentry{naive}
        \addplot[
          color=blue,
          mark=square,
          ]
          coordinates {
            (1, 11.231875) (2, 12.879500) (4, 16.851930) (8, 24.666485) (16, 42.054055) (32, 76.369778)
          };
        \addlegendentry{incremental}
        \addplot[
          color=orange,
          mark=o,
          ]
          coordinates {
            (1, 19.405222) (2, 33.487472) (4, 80.107597) (8, 284.954791) (16, 1536.089624) (32, 10721.729861)
          };
        \addplot[
          color=blue,
          mark=o,
          ]
          coordinates {
            (1, 25.892069) (2, 40.031930) (4, 69.446902) (8, 130.640986) (16, 260.653917) (32, 481.827902)
          };
      \end{axis}
    \end{tikzpicture}
    % graph \includegraphics[width=.4\linewidth]{image1}
    \caption{Independence benchmark}
    \label{fig:indep}
  \end{subfigure}
  \caption{The above results depict the behavior of both algorithms in a context where there is a lot of work that can be reused (Transitivity) and no work to be reused (Independence). The lines with square entry points represent problems where unification is easy. The lines with circle entry points are the same tests with hard unification problems.}
  \label{fig:benchmark}
  \end{figure}

The results in Fig.~\ref{fig:trans} are unsurprising.
The naive algorithm goes over the context, containing initially $n$ hypotheses, and compares all hypotheses pairwise.
This is repeated approximately for each of the $n(n-1)/2$ added hypotheses, so the overall complexity is $O(n^4)$.
The incremental algorithm considers each hypothesis only once.
As the hypotheses get matched to both slots, it then compares each hypothesis with at most $n$ other hypotheses.
This yields a complexity of $O(n^2)$.

Either algorithm generates all possible transitivity chains.
If only the longest such chain, from $a$ to $a + n$, is needed, the transitivity rule can be registered as a \emph{destruct} rule, a special sort of forward rule that, whenever it is applied to certain hypotheses, removes the hypotheses from the context.
This reduces the complexity of the incremental algorithm to $O(n)$.

\paragraph{Independent Rules.}
In the last example, part of the stateful algorithm's success stems from the fact that it could reuse a lot of its previous work.
An obvious question is then how well does the stateful algorithm work when there is no work to be reused.

Given a set of propositions $\mathcal{P} := \{P_{i,j} | 1 \leq i \leq n \text{ and } 1 \leq j \leq 6\}$ and $\mathcal{Q} :=\{Q_{i} | 1 \leq i \leq n \}$, in this test, we consider the $n$ following rules $r_i : P_{i,1}\to \dots P_{i,6} \to Q_i$.
The procedures are then run on a context containing exactly $\mathcal{P}$.
In this case, we sketch the behavior of the stateless algorithm:
It pick a first hypothesis, $h_{i,j} : P_{i,j}$.
If $j < 6$, the index returns nothing and it selects another hypothesis.
For $h_{i,6} : P_{i,6}$, the rule $r_i$ is selected, and it then needs to try and fill its remaining five slot with the context's $6n$ hypotheses which it tries all.
This gives a complexity of about $O(n^2)$.

For the stateful algorithm, the hypotheses are considered one by one and match directly to the rule and the slot.
The expected complexity is then linear in the number of rules.

\paragraph{Rules of Varying Depth.}
In Fig.~\ref{fig:erase}, the step is set up as follows: given some rule $r$ with $6$ \xcom{motivate 6} premises, we run the procedure in a context with 5 of the 6 premises present.
The numbers on the $x$ axis represent which hypothesis is missing in the order of consideration by the algorithm.
In a sense, this is how \textit{deep} the algorithm investigate before it stops.
At $0$, the rule are not selected by the index so the procedure stops.
The stateless algorithm gets progressively slower the further the removed premises is located.

\begin{figure}
  \centering
  \begin{subfigure}{.5\textwidth}
    \centering
    \begin{tikzpicture}[scale=0.75]
      \begin{axis}[
        title={Depth Test},
        xlabel={Depth},
        ylabel={Time in ms},
        xmin=1, xmax=6,
        ymin=0, ymax=650,
        xtick={1,2,3,4,5,6},
        ytick={2^2,2^4,2^6,2^8},
        ymode=log,
        log basis y=2,
        legend pos=north west,
        ymajorgrids=true,
        grid style=dashed,
        legend image post style={mark=},
        ]
        \addplot[
          color=orange,
          mark=square,
          ]
          coordinates {
            (1, 32.580083) (2, 33.212805) (3, 40.239833) (4, 47.670277) (5, 54.647458) (6, 61.044958) 
          };
        \addlegendentry{naive}
        \addplot[
          color=blue,
          mark=square,
          ]
          coordinates {
            (1, 127.925541) (2, 140.497597) (3, 123.719264) (4, 130.819361) (5, 121.047667) (6, 123.789500)
          };
        \addlegendentry{incremental}
        \addplot[
          color=orange,
          mark=o,
          ]
          coordinates {
            (1, 108.120444) (2, 107.352694) (3, 116.182833) (4, 125.995639) (5, 137.815527) (6, 142.310597) 
          };
        \addplot[
          color=blue,
          mark=o,
          ]
          coordinates {
            (1, 604.595791) (2, 624.541194) (3, 608.671111) (4, 614.285014) (5, 588.636819) (6, 595.276806) 
          };
      \end{axis}
    \end{tikzpicture}
    \caption{Depth benchmark no-precompilation}
    \label{fig:erase-noprecomp}
  \end{subfigure}%
  \begin{subfigure}{.5\textwidth}
    \centering
    \begin{tikzpicture}[scale=0.75]
      \begin{axis}[
        title={Depth Test},
        xlabel={Depth},
        %ylabel={Time in ms},
        xmin=1, xmax=6,
        ymin=0, ymax=128,
        xtick={1,2,3,4,5,6},
        ytick={2^1,2^3,2^5,2^7},
        ymode=log,
        log basis y=2,
        legend pos=north west,
        ymajorgrids=true,
        grid style=dashed,
        legend image post style={mark=},
        ]
        \addplot[
          color=orange,
          mark=square,
          ]
          coordinates {
            (1, 12.820514) (2, 12.645666) (3, 17.582138) (4, 22.730528) (5, 27.280097) (6, 32.578722) 
          };
        \addlegendentry{naive}
        \addplot[
          color=blue,
          mark=square,
          ]
          coordinates {
            (1, 13.406416) (2, 13.747139) (3, 12.503764) (4, 12.950486) (5, 12.282083) (6, 12.151930) 
          };
        \addlegendentry{incremental}
        \addplot[
          color=orange,
          mark=o,
          ]
          coordinates {
            (1, 83.032819) (2, 79.396889) (3, 85.939180) (4, 92.495542) (5, 96.461291) (6, 105.517458)
          };
        \addplot[
          color=blue,
          mark=o,
          ]
          coordinates {
            (1, 25.681583) (2, 25.322444) (3, 27.672833) (4, 26.999055) (5, 25.690319) (6, 25.257291)
          };
      \end{axis}
    \end{tikzpicture}
    % graph \includegraphics[width=.4\linewidth]{image1}
    \caption{Depth benchmark with precompilation}
    \label{fig:erase-precomp}
  \end{subfigure}
  \caption{The above results depict the behavior of both algorithms in depending on the \text{depth} of potential partial matches. The lines with square entry points represent problems where unification is easy. The lines with circle entry points are the same tests with hard unification problems.}
  \label{fig:erase}
  \end{figure}

The position of the missing premise has little effect on the stateful algorithm as the index selects the rule in all case; it only needs one of the premise to be present.
The work the stateful algorithm has to do is thus close to constant in this scenario.

\section{Related Work}

\paragraph{ACL2.}
Among white-box proof automation tactics, only ACL2's \enquote{waterfall} (TODO ref) has special support for forward reasoning.
(Some such tactics, e.g.\ Coq's auto, can execute arbitrary tactics including forward rules, but make no special provisions for them.)
It uses essentially Aesop's naive algorithm, i.e.\ the context of each goal is saturated independently without reusing partial results from other goals.
ACL2 additionally supports \emph{trigger terms}, which allow forward rules to be selected based on the presence of a particular term anywhere in the goal, rather than based on particular hypotheses.
Aesop implements a similar mechanism, \emph{rule patterns}, not described here due to space constraints.

\paragraph{SATCHMO.}
The Prolog-based first-order theorem prover SATCHMO (TODO ref) and its many descendants (TODO refs) use a tableau calculus (TODO ref) that can be viewed as combined forward and backward reasoning.
Given a set of implications $A₁ ∧ \dots ∧ Aₙ → B₁ ∨ \dots ∨ Bₘ$, SATCHMO attempts to create a model that satisfies all implications.
Its search procedure is a special case of our technique: the implications are used as forward rules and a single backward rule splits any goal with target $B₁ ∨ \dots ∨ Bₘ$ into goals with targets $B₁, \dots, Bₘ$.
This is a simpler setting than ours since the backward rule does not change the facts available to the forward rules.
Still, our technique has the advantage that at each branching point we remember the partial matches induced by the currently known facts for each implication, rather than matching the implication against the database multiple times.

\paragraph{Knowledge-based reasoning systems.}
Combined forward and backward reasoning is also supported by some knowledge-based reasoning systems, e.g.\ Algernon (TODO ref) and EYE (TODO ref).
To our knowledge, none of these systems have backwards rules that can change the facts available to forward rules.
Nevertheless, our proposal bears some resemblance to the RETE algorithm (TODO ref) for forward reasoning in large knowledge bases.

\jcom{auto2?}

\section{Conclusion}

We have presented a technique that integrates forward reasoning into a tree-based proof search procedure supporting arbitrary proof rules.
We avoid redundant reasoning steps by caching partial forward rule applications in a data structure, the \emph{forward match state}, that enables efficient updates.
The technique is independent of the search strategy and logic used.
Our evaluation shows a substantial speedup on some synthetic benchmarks, relative to Aesop's previous implementation.
\end{document}
